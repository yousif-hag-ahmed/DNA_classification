{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "word2vec with cnn .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48a4a6e7e4c64e8fa2c2aa6028e7b35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e89ed39de7dd47d1bc2b1297d8507837",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a77a7322079a4085bbe3bbf7ef11d782",
              "IPY_MODEL_a61bba76438a42ceaf9c2894be36398a",
              "IPY_MODEL_acf17540383d4c55952391edcd642745"
            ]
          }
        },
        "e89ed39de7dd47d1bc2b1297d8507837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a77a7322079a4085bbe3bbf7ef11d782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_042799136d434a948618ce6db39bd518",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dad235c48d3643d2b39e59cbd444094a"
          }
        },
        "a61bba76438a42ceaf9c2894be36398a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80558e4005f24f98bbdfd1399672114c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8e407256ea645d7b16fff44b31060e1"
          }
        },
        "acf17540383d4c55952391edcd642745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07785605d00f45f68c291f37af8b250c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 71.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6b6e9b7862e4cb281d84c31e2d1da5b"
          }
        },
        "042799136d434a948618ce6db39bd518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dad235c48d3643d2b39e59cbd444094a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80558e4005f24f98bbdfd1399672114c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8e407256ea645d7b16fff44b31060e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07785605d00f45f68c291f37af8b250c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6b6e9b7862e4cb281d84c31e2d1da5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"/content/drive\")\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import datasets ,models, transforms\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torchsummary import summary\r\n",
        "\r\n",
        "\r\n",
        "from __future__ import print_function, division\r\n",
        "\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import os\r\n",
        "import copy\r\n",
        "\r\n",
        "plt.ion()   # interactive mode\r\n",
        "\r\n",
        "#  https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/62840b1eece760d5e42593187847261f/transfer_learning_tutorial.ipynb#scrollTo=dF0_RiFvCP4s\r\n",
        "\r\n",
        "\r\n",
        "import torch; torch.manual_seed(0)\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.utils\r\n",
        "import torch.distributions\r\n",
        "import torchvision\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\r\n",
        "\r\n",
        "\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "from torchvision.io import read_image\r\n",
        "#!pip install --upgrade gensim\r\n",
        "from gensim.models import Word2Vec\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok8pMTGgADs8",
        "outputId": "20d45790-66cf-4f7e-ed92-4eb752fa76e2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "fLW33suiAX9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "train_features_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_features.csv'\r\n",
        "test_features_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/test_features.csv'\r\n",
        "train_labels_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_labels.csv'\r\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_labels - Copy.csv'\r\n",
        "def get_word2v (path):\r\n",
        "  test = pd.read_csv(path)\r\n",
        "  print(test.head())\r\n",
        "  train = test['dna'].values.tolist()\r\n",
        "\r\n",
        "  # print(len(train)) 121\r\n",
        "  DNA_list = []\r\n",
        "  for DNA in train:\r\n",
        "    DNA = list(DNA)\r\n",
        "    DNA_list.append(DNA)\r\n",
        "  model = Word2Vec(DNA_list , vector_size = 10 , min_count= 1 )\r\n",
        "  print(model , model.wv.key_to_index )\r\n",
        " \r\n",
        "  \r\n",
        "  vectorized = []\r\n",
        "  for vec in DNA_list:\r\n",
        "    v = np.array([])\r\n",
        "    for char in vec :\r\n",
        "      char = model.wv[char]\r\n",
        "      v= np.append(v ,char)\r\n",
        "    vectorized.append(v)\r\n",
        "\r\n",
        "  return vectorized,model\r\n",
        "\r\n",
        "\r\n",
        "# print(DNA_list)=['T', 'A', 'C', 'A', 'T', 'T', 'A', 'T', 'A', 'T', 'T', 'T', 'T', 'A', 'T', 'T', 'T', 'T', 'T', 'G', 'G', 'A', 'A', 'T', 'T', .......\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "QbmEfcTjMk_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "\n",
        "def get_word2v_vectorsOnly (path,model):\n",
        "  test = pd.read_csv(path)\n",
        "  print(test.head())\n",
        "  train = test['dna'].values.tolist()\n",
        "\n",
        "  # print(len(train)) 121\n",
        "  DNA_list = []\n",
        "  for DNA in train:\n",
        "    DNA = list(DNA)\n",
        "    DNA_list.append(DNA)\n",
        "  vectorized = []\n",
        "  for vec in DNA_list:\n",
        "    v = np.array([])\n",
        "    for char in vec :\n",
        "      char = model.wv[char]\n",
        "      v= np.append(v ,char)\n",
        "    vectorized.append(v)\n",
        "\n",
        "  return vectorized"
      ],
      "outputs": [],
      "metadata": {
        "id": "NY46GQf8OhX1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "\n",
        "class CustomDNADataset(Dataset):\n",
        "    def __init__(self, feature_matrix,label_file, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(label_file)\n",
        "        self.img_features =feature_matrix\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        " ############# DNA transform ######################     \n",
        "        DNA = self.img_features[idx]\n",
        "\n",
        "        #print(len(DNA))\n",
        "\n",
        "        n = np.array(DNA)# 10*dim*12090\n",
        "        if len(DNA) < 6000 :\n",
        "\n",
        "          Our_pad =6000-len(DNA)\n",
        "          #print(len(DNA))\n",
        "          \n",
        "          for pad in range(Our_pad):# we pad the end of the sequence with zeros \n",
        "            n =np.append(n,[0,0,0,0,0,0,0,0,0,0])\n",
        "\n",
        "        #print(n.shape)\n",
        "        l = np.array(n , dtype=np.float32)\n",
        "        #print(l.shape)\n",
        "        Data_array = torch.from_numpy(l[0:6000])#crop first 800 features 3*22*22*10\n",
        "\n",
        "        DNA_image = Data_array.reshape(3,40,50)\n",
        "\n",
        "\n",
        "#################################################\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        # we get the labels from a different file \n",
        "\n",
        "        return DNA_image, label"
      ],
      "outputs": [],
      "metadata": {
        "id": "gOzB2VTfzjeW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# train_features_path = '/Users/yousi/Untitled Folder/dna-barcode-classification/data/train_features.csv'\n",
        "# #test_features_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/test_features.csv'\n",
        "# train_labels_path = '/Users/yousi/Untitled Folder/dna-barcode-classification/data/train_labels.csv'\n",
        "\n",
        "\n",
        "vectorized , model_w2vec =  get_word2v(train_features_path)\n",
        "\n",
        "full_dataset= CustomDNADataset(vectorized,label_file=train_labels_path)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                                dna\n",
            "0   1  AACATTATACTTTATTTTCGGAGCATGATCAGGAATAGTAGGAACT...\n",
            "1   2  TACACTATACTTCATTTTTGGTGCTTGAGCAGGAATGCTAGGAACA...\n",
            "2   3  ----------------------------------------------...\n",
            "3   4  AACATTATATTTTATTTTTGGTGCATGAGCTGGAATAGTAGGAACT...\n",
            "4   5  AACTTTATATTTTATTTTTGGAGCTTGAGCTGGAATAGTTGGAACA...\n",
            "Word2Vec(vocab=12, vector_size=10, alpha=0.025) {'T': 0, 'A': 1, 'C': 2, 'G': 3, '-': 4, 'N': 5, 'Y': 6, 'W': 7, 'R': 8, 'M': 9, 'S': 10, 'K': 11}\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSDS9VXg3jYS",
        "outputId": "60cfa2c3-09c6-4812-903b-594507c3c21c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# for i, (images, labels) in enumerate(full_dataset):\n",
        "#   print(i ,images.shape , labels)"
      ],
      "outputs": [],
      "metadata": {
        "id": "t4mVZeJC3zYz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# test_features_path = '/Users/yousi/Untitled Folder/dna-barcode-classification/data/test_features.csv'\n",
        "# test_labels_path = '/Users/yousi/Untitled Folder/dna-barcode-classification/data/train_labels - Copy.csv'\n",
        "\n",
        "\n",
        "vectorized_test = get_word2v_vectorsOnly(test_features_path,model_w2vec)\n",
        "\n",
        "#full_dataset= CustomDNADataset(feature_file=train_features_path,label_file=train_labels_path)\n",
        "# so pass the whole set by specifing the path of file to be inputed to our custum class \n",
        "\n",
        "Test_dataset = CustomDNADataset(vectorized_test,label_file=test_labels_path)\n",
        "# for the test_dataset I am using fake label data which is not accually there just so that I can use \n",
        "# my custom class , it has the same len as the train data ( I choped some in csv file )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                                dna\n",
            "0   1  AATACTTTATTTTATTTTTGCTATATGAGCTGGAATAATTGGAGCT...\n",
            "1   2  GGAGTATGATCTGGAATAGTCGGAACTTCTCTAAGAATTTTAATTC...\n",
            "2   3  TACTTTATACTTTATTTTTGGAGCATGATCAGGAATAGTAGGAACT...\n",
            "3   4  GATATTATATTTTATTTTTGGAATATGATCAGGAATAGTAGGAAGA...\n",
            "4   5  ----------------------------------------------...\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcc3awJy7Rs7",
        "outputId": "659b1107-6aea-47fd-efdf-f81dae17d2e7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "train_size = int(0.95 * len(full_dataset))\n",
        "# this is a creative way to create a validation set by spliting the dataset \n",
        "validation_size = len(full_dataset) - train_size\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(full_dataset, [train_size, validation_size])\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "4AVyQ4D7-1_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "dataloaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=15,\n",
        "                                             shuffle=True, num_workers=2),\n",
        "               'val' : torch.utils.data.DataLoader(validation_dataset, batch_size=15,\n",
        "                                             shuffle=True, num_workers=2)}\n",
        "dataset_sizes = {'train': len(train_dataset) ,\n",
        "                 'val' : len(validation_dataset)}\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "1NUyN34X7wZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        " \n",
        "\n",
        "\n",
        "# hyper parameters \n",
        "input_size = 36*36\n",
        "in_channel = 3\n",
        "num_classes = 1214\n",
        "learning_rate = 0.001\n",
        "batch_size = 15\n",
        "# the batch size appered to be a significant factor on the effectivness of the training\n",
        "# 15 is found to be a good num \n",
        "num_epochs = 3\n",
        "#\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "9-7Z3wHI_m-O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "skPo9QCb_t1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "outputs": [],
      "metadata": {
        "id": "NfY_8dkv_-Bu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a4a6e7e4c64e8fa2c2aa6028e7b35c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "48a4a6e7e4c64e8fa2c2aa6028e7b35c",
            "e89ed39de7dd47d1bc2b1297d8507837",
            "a77a7322079a4085bbe3bbf7ef11d782",
            "a61bba76438a42ceaf9c2894be36398a",
            "acf17540383d4c55952391edcd642745",
            "042799136d434a948618ce6db39bd518",
            "dad235c48d3643d2b39e59cbd444094a",
            "80558e4005f24f98bbdfd1399672114c",
            "c8e407256ea645d7b16fff44b31060e1",
            "07785605d00f45f68c291f37af8b250c",
            "c6b6e9b7862e4cb281d84c31e2d1da5b"
          ]
        },
        "id": "dzgmj4QF__J7",
        "outputId": "d7230960-7410-4f6f-c3f4-09b53f6793e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=20)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 1.4506 Acc: 0.8379\n",
            "val Loss: 1.0694 Acc: 0.8529\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.7976 Acc: 0.9090\n",
            "val Loss: 0.7200 Acc: 0.9040\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.5034 Acc: 0.9400\n",
            "val Loss: 0.5755 Acc: 0.9241\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3446 Acc: 0.9563\n",
            "val Loss: 0.4762 Acc: 0.9396\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2351 Acc: 0.9698\n",
            "val Loss: 0.4063 Acc: 0.9427\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.1669 Acc: 0.9764\n",
            "val Loss: 0.4202 Acc: 0.9443\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.0964 Acc: 0.9889\n",
            "val Loss: 0.3720 Acc: 0.9551\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.0763 Acc: 0.9929\n",
            "val Loss: 0.3645 Acc: 0.9520\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.0672 Acc: 0.9949\n",
            "val Loss: 0.3664 Acc: 0.9536\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.0626 Acc: 0.9958\n",
            "val Loss: 0.3630 Acc: 0.9567\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.0599 Acc: 0.9961\n",
            "val Loss: 0.3648 Acc: 0.9536\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.0555 Acc: 0.9968\n",
            "val Loss: 0.3642 Acc: 0.9582\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.0528 Acc: 0.9974\n",
            "val Loss: 0.3610 Acc: 0.9551\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.0483 Acc: 0.9978\n",
            "val Loss: 0.3562 Acc: 0.9551\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.0486 Acc: 0.9980\n",
            "val Loss: 0.3536 Acc: 0.9598\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.0487 Acc: 0.9981\n",
            "val Loss: 0.3580 Acc: 0.9567\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.0474 Acc: 0.9987\n",
            "val Loss: 0.3597 Acc: 0.9551\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.0479 Acc: 0.9980\n",
            "val Loss: 0.3583 Acc: 0.9567\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.0475 Acc: 0.9980\n",
            "val Loss: 0.3550 Acc: 0.9551\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.0471 Acc: 0.9985\n",
            "val Loss: 0.3590 Acc: 0.9582\n",
            "\n",
            "Training complete in 54m 49s\n",
            "Best val Acc: 0.959752\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyxm6X2e__Na",
        "outputId": "247d5743-e258-4d32-d64d-2c5d09f85e09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "test_loader = DataLoader(Test_dataset  , batch_size=1 , shuffle=False)\n",
        "def write_csv_results (loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    your_file = open('word2vec_transferLearningCNN_30.csv', 'ab')\n",
        "    # we create a csv file or open it 'ab' for append binery \n",
        "    sm = torch.nn.Softmax()\n",
        "    # we use a softmax to compute the probability of each guess of the network \n",
        "    \n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x,_ in loader:\n",
        "        x = x.to(device = device )\n",
        "       \n",
        "        \n",
        "        scores = model(x)\n",
        "        _,prediction = scores.max(1)\n",
        "        #print(scores.max())\n",
        "        #print('model prediction = ',prediction , 'y = ',y)\n",
        "        probabilities = sm(scores) \n",
        "        #print(probabilities.max())\n",
        "        #print(prediction)\n",
        "        if probabilities.max() < 0.30 :\n",
        "          prediction = torch.tensor([-1])\n",
        "          np.savetxt(your_file,prediction.cpu())\n",
        "          # we save the prediction in the open file but first we have to \n",
        "          # send it back to being a cpu \n",
        "        else:\n",
        "          np.savetxt(your_file,prediction.cpu().numpy())  \n",
        "        \n",
        "        \n",
        "\n",
        "      model.train()\n",
        "      your_file.close()\n",
        "\n",
        "write_csv_results(test_loader,model_ft)\n",
        "# using our def \n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skd55N1YAv22",
        "outputId": "57b63f80-73c8-493a-9224-f16cce910b18"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "tmNfE5-aJm8L"
      }
    }
  ]
}