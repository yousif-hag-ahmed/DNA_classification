{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of transferLearning_ kaggleComp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "881e331fca364f5a825faa60c3111b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b61c8e0968d4e198f4c879e2ed6562d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa16c0ee58d641c29569f0f906510e6f",
              "IPY_MODEL_f9c1732a3f2e4b3fb853a847c0a0b008",
              "IPY_MODEL_fa664c3682b04a1a949e7e5d9d9adffe"
            ]
          }
        },
        "8b61c8e0968d4e198f4c879e2ed6562d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa16c0ee58d641c29569f0f906510e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acaad25b01284435bf87cb6eb16d1f06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4f93f144d99413fbd330d5db1fe1ec9"
          }
        },
        "f9c1732a3f2e4b3fb853a847c0a0b008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_139e2777971c4f279798331499823f90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2d2362cc66d4156aabe7d20be6abeaf"
          }
        },
        "fa664c3682b04a1a949e7e5d9d9adffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2e437c3cfca4f7fab42a4d7e6fc6c38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:01&lt;00:00, 49.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_079dc8edc15b427c9244a9931561946b"
          }
        },
        "acaad25b01284435bf87cb6eb16d1f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4f93f144d99413fbd330d5db1fe1ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "139e2777971c4f279798331499823f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2d2362cc66d4156aabe7d20be6abeaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2e437c3cfca4f7fab42a4d7e6fc6c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "079dc8edc15b427c9244a9931561946b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "from torchvision import datasets ,models, transforms\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from __future__ import print_function, division\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "from torchvision import datasets, models, transforms\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import time\r\n",
        "import os\r\n",
        "import copy\r\n",
        "\r\n",
        "plt.ion()   # interactive mode\r\n",
        "\r\n",
        "#  https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/62840b1eece760d5e42593187847261f/transfer_learning_tutorial.ipynb#scrollTo=dF0_RiFvCP4s\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "kSeXdD8BJhXP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "from torchvision.io import read_image\r\n",
        "\r\n",
        "class CustomDNADataset(Dataset):\r\n",
        "    def __init__(self, feature_file,label_file, transform=None, target_transform=None):\r\n",
        "        self.img_labels = pd.read_csv(label_file)\r\n",
        "        self.img_features = pd.read_csv(feature_file)\r\n",
        "        # pandas read the data \r\n",
        "        self.transform = transform\r\n",
        "        self.target_transform = target_transform\r\n",
        "        # no transform is used here \r\n",
        "        #self.dic= {'-':0,'A' :2**2 , 'C':2**4,'T':2**6,'G':2**7,'N':0}\r\n",
        "        self.dic= {'-':[0,0,0,0],'A' :[1,0,0,0] , 'C':[0,1,0,0],'T':[0,0,1,0],'G':[0,0,0,1]}\r\n",
        "        # I learned the sequence of dana from file:///D:/downloads/dna-and-animal-classification.pdf\r\n",
        "        #and from http://ircamera.as.arizona.edu/Astr2016/text/nucleicacid1.htm \r\n",
        "        # which showed that there are 4 dominante letters to determine the sequence\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.img_labels)\r\n",
        "        # this is just the number rows or samples in the input data as used by \r\n",
        "        # Dataset class \r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        " ############# DNA transform ######################     \r\n",
        "        DNA = self.img_features.iloc[idx,1]\r\n",
        "        # so DNA is getting the img_features panda csv read and we are taking the second\r\n",
        "        #colmn , the first is just ids . idx is generated by pytorch randomly depending on\r\n",
        "        # if we shuffle the data or not and the number of batch size (part of Dataset class which\r\n",
        "        # we inheret from )\r\n",
        "\r\n",
        "\r\n",
        "        n = np.array([])\r\n",
        "        Our_pad = (3*22*22)-len(DNA)\r\n",
        "        # here I am using 1296 which is 36*36 , I choose this number based on \r\n",
        "        # the maximum individual row I found which was around 1058 ,this is used to \r\n",
        "        # generate a padding which is some how consistent along all .I also chose \r\n",
        "        # 36 so that when we do conv and maxpool we get a nice number which is \r\n",
        "        # dividable by 2 How to fix RuntimeError \"Expected object \r\n",
        "        #of scalar type Float but got scalar type Double for argument\"\r\n",
        "        # here to get the right dim we muliply by 2 the in dim \r\n",
        "        \r\n",
        "        for i in range(len(DNA)):# DNA is our row where we itterate \r\n",
        "\r\n",
        "          if DNA[i] in self.dic:\r\n",
        "            mut = self.dic[DNA[i]]\r\n",
        "            mut = [x * 2 for x in mut]\r\n",
        "\r\n",
        "            n = np.append(n,mut)\r\n",
        "          else:\r\n",
        "            n= np.append(n,[0,0,0,0])\r\n",
        "          \r\n",
        "          \r\n",
        "        for pad in range(Our_pad):# we pad the end of the sequence with zeros \r\n",
        "          n =np.append(n,[0,0,0,0])\r\n",
        "\r\n",
        "        \r\n",
        "        l = np.array(n , dtype=np.float32)\r\n",
        "        # this was very trick where the base type of any np array is float 64 or \r\n",
        "        # double but the base type for torch is float 32 so if we convert \r\n",
        "        # a np array to torch we need to first change it to float32 or we get an error \r\n",
        "        # which says \r\n",
        "        Data_array = torch.from_numpy(l)\r\n",
        "        #transfer a np to torch \r\n",
        "        #DNA_dense = Data_array\r\n",
        "        # depending on the type of network we can keep it flat or \r\n",
        "        # change the dim (resh\r\n",
        "        DNA_image = Data_array.reshape(3,44,44)\r\n",
        "\r\n",
        "        # reshape the dim to be in the form of an image of pix 1 which is \r\n",
        "        # usally the RGB or gray channel , in our case it is gray ,\r\n",
        "        # then 36 by 36 which what our padding is doing \r\n",
        "        #for a 3 chennel image insted of 1 \r\n",
        "\r\n",
        "\r\n",
        "#################################################\r\n",
        "        label = self.img_labels.iloc[idx, 1]\r\n",
        "        # we get the labels from a different file \r\n",
        "\r\n",
        "        return DNA_image, label"
      ],
      "outputs": [],
      "metadata": {
        "id": "FZucOaWqCTPX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "\r\n",
        "# n = np.array([])\r\n",
        "# Our_pad = (3*22*22)-len(DNA1)\r\n",
        "# # here I am using 1296 which is 36*36 , I choose this number based on \r\n",
        "# # the maximum individual row I found which was around 1058 ,this is used to \r\n",
        "# # generate a padding which is some how consistent along all .I also chose \r\n",
        "# # 36 so that when we do conv and maxpool we get a nice number which is \r\n",
        "# # dividable by 2 How to fix RuntimeError \"Expected object \r\n",
        "# #of scalar type Float but got scalar type Double for argument\"\r\n",
        "# j = 0 #index\r\n",
        "# for i in DNA1:# DNA is our row where we itterate \r\n",
        "  \r\n",
        "#   if i in dic:\r\n",
        "#     mut = dic[i]\r\n",
        "#     mut[3] = j\r\n",
        "#     n = np.append(n,mut)\r\n",
        "#   else:\r\n",
        "#     n= np.append(n,[1,1,1,j])\r\n",
        "#   j+=1\r\n",
        "# for pad in range(Our_pad):# we pad the end of the sequence with zeros \r\n",
        "#   n =np.append(n,[0,0,0,0])\r\n",
        "\r\n",
        "# print(n.shape)\r\n",
        "# l = np.array(n , dtype=np.float32)\r\n",
        "# # this was very trick where the base type of any np array is float 64 or \r\n",
        "# # double but the base type for torch is float 32 so if we convert \r\n",
        "# # a np array to torch we need to first change it to float32 or we get an error \r\n",
        "# # which says \r\n",
        "# Data_array = torch.from_numpy(l)\r\n",
        "# #transfer a np to torch \r\n",
        "# #DNA_dense = Data_array\r\n",
        "# # depending on the type of network we can keep it flat or \r\n",
        "# # change the dim (resh\r\n",
        "# DNA_image = Data_array.reshape(3,44,44)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "vS3OOnyZt39C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "im = torch.ones(1,36,36)\r\n",
        "im.shape\r\n",
        "im = im.repeat(3,1,1)\r\n",
        "\r\n",
        "im.shape\r\n",
        "\r\n",
        "l = [0,0,1,0]\r\n",
        "l = [x * 2 for x in l]\r\n",
        "print(l)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 2, 0]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsniYJsGO640",
        "outputId": "5ad488ce-67f0-4f32-9489-7ffc3ff6ff73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "train_features_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_features.csv'\r\n",
        "test_features_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/test_features.csv'\r\n",
        "train_labels_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_labels.csv'\r\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/deep learning CSCI570/deep learning course/dna-barcode-classification/train_labels - Copy.csv'\r\n",
        "\r\n",
        "\r\n",
        "full_dataset= CustomDNADataset(feature_file=train_features_path,label_file=train_labels_path)\r\n",
        "# so pass the whole set by specifing the path of file to be inputed to our custum class \r\n",
        "\r\n",
        "Test_dataset = CustomDNADataset(feature_file=test_features_path,label_file=test_labels_path)\r\n",
        "# for the test_dataset I am using fake label data which is not accually there just so that I can use \r\n",
        "# my custom class , it has the same len as the train data ( I choped some in csv file )"
      ],
      "outputs": [],
      "metadata": {
        "id": "7bCRNEWgneDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "len(full_dataset)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12906"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFURohSJ6PrM",
        "outputId": "cdd4bd69-070c-425e-949e-f363cd91e54b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "train_size = int(0.80 * len(full_dataset))\r\n",
        "# this is a creative way to create a validation set by spliting the dataset \r\n",
        "validation_size = len(full_dataset) - train_size\r\n",
        "train_dataset, validation_dataset = torch.utils.data.random_split(full_dataset, [train_size, validation_size])\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "oCo0WyqQCoFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "dataloaders = {'train': torch.utils.data.DataLoader(train_dataset, batch_size=15,\r\n",
        "                                             shuffle=True, num_workers=2),\r\n",
        "               'val' : torch.utils.data.DataLoader(validation_dataset, batch_size=15,\r\n",
        "                                             shuffle=True, num_workers=2)}\r\n",
        "dataset_sizes = {'train': len(train_dataset) ,\r\n",
        "                 'val' : len(validation_dataset)}\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "Rr4SeMT6LbPu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# set device\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        " \r\n",
        "\r\n",
        "\r\n",
        "# hyper parameters \r\n",
        "input_size = 36*36\r\n",
        "in_channel = 1\r\n",
        "num_classes = 1214\r\n",
        "learning_rate = 0.001\r\n",
        "batch_size = 15\r\n",
        "# the batch size appered to be a significant factor on the effectivness of the training\r\n",
        "# 15 is found to be a good num \r\n",
        "num_epochs = 3\r\n",
        "#\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "clnCengJ-Yvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "XYSEkhF0N4jT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "i2uIUrDHCP4v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zYrLz-yLCP4x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "881e331fca364f5a825faa60c3111b1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "QvM5XDWZCP4x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "881e331fca364f5a825faa60c3111b1f",
            "8b61c8e0968d4e198f4c879e2ed6562d",
            "aa16c0ee58d641c29569f0f906510e6f",
            "f9c1732a3f2e4b3fb853a847c0a0b008",
            "fa664c3682b04a1a949e7e5d9d9adffe",
            "acaad25b01284435bf87cb6eb16d1f06",
            "d4f93f144d99413fbd330d5db1fe1ec9",
            "139e2777971c4f279798331499823f90",
            "c2d2362cc66d4156aabe7d20be6abeaf",
            "c2e437c3cfca4f7fab42a4d7e6fc6c38",
            "079dc8edc15b427c9244a9931561946b"
          ]
        },
        "outputId": "554552da-f8a0-496b-a97e-6a41a2bb8e3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 5.2824 Acc: 0.2501\n",
            "val Loss: 3.1378 Acc: 0.5411\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 2.3560 Acc: 0.7184\n",
            "val Loss: 1.4104 Acc: 0.8280\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.0069 Acc: 0.9087\n",
            "val Loss: 0.6595 Acc: 0.9191\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.4815 Acc: 0.9592\n",
            "val Loss: 0.4113 Acc: 0.9454\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.2519 Acc: 0.9801\n",
            "val Loss: 0.3104 Acc: 0.9547\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.1446 Acc: 0.9906\n",
            "val Loss: 0.2771 Acc: 0.9578\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.0885 Acc: 0.9956\n",
            "val Loss: 0.2590 Acc: 0.9613\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.0572 Acc: 0.9981\n",
            "val Loss: 0.2536 Acc: 0.9617\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0516 Acc: 0.9985\n",
            "val Loss: 0.2525 Acc: 0.9609\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0477 Acc: 0.9987\n",
            "val Loss: 0.2494 Acc: 0.9605\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0466 Acc: 0.9986\n",
            "val Loss: 0.2486 Acc: 0.9613\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0433 Acc: 0.9989\n",
            "val Loss: 0.2476 Acc: 0.9617\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0436 Acc: 0.9985\n",
            "val Loss: 0.2514 Acc: 0.9609\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cc88ea5f8bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=25)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-1a5d4f162548>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sCZXJlBrCP4y",
        "outputId": "041f274e-e173-4ebd-939b-748a530487b0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "test_loader = DataLoader(Test_dataset  , batch_size=1 , shuffle=False)\n",
        "def write_csv_results (loader,model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    your_file = open('resultsWithforeign_75_transferLearningCNN.csv', 'ab')\n",
        "    # we create a csv file or open it 'ab' for append binery \n",
        "    sm = torch.nn.Softmax()\n",
        "    # we use a softmax to compute the probability of each guess of the network \n",
        "    \n",
        "    \n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x,_ in loader:\n",
        "        x = x.to(device = device )\n",
        "       \n",
        "        \n",
        "        scores = model(x)\n",
        "        _,prediction = scores.max(1)\n",
        "        #print(scores.max())\n",
        "        #print('model prediction = ',prediction , 'y = ',y)\n",
        "        probabilities = sm(scores) \n",
        "        #print(probabilities.max())\n",
        "        #print(prediction)\n",
        "        if probabilities.max() < 0.95 :\n",
        "          prediction = torch.tensor([-1])\n",
        "          np.savetxt(your_file,prediction.cpu())\n",
        "          # we save the prediction in the open file but first we have to \n",
        "          # send it back to being a cpu \n",
        "        else:\n",
        "          np.savetxt(your_file,prediction.cpu().numpy())  \n",
        "        \n",
        "        \n",
        "\n",
        "      model.train()\n",
        "      your_file.close()\n",
        "\n",
        "write_csv_results(test_loader,model_ft)\n",
        "# using our def \n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ],
      "metadata": {
        "id": "l0gw1rULGaiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf8e0ff-a094-4400-8c38-73d6735cabd8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#model = NN(input_size,num_classes).to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "K6yKndOhlb2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "torch.save(model_ft.state_dict(), '/content/transfer_learning_firstrun_RGB_imagenet_model.pt')\n",
        "# save the model to the Path which saves the state_dict(from url https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bv_ZZh3J60WR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "  "
      ],
      "outputs": [],
      "metadata": {
        "id": "5oiLdwchNts_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "GEahAqcqrGpJ"
      }
    }
  ]
}